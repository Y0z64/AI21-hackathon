{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**STORIES**\n",
        "###Made by: (Y0z64)[https://github.com/Y0z64]\n",
        "\n"
      ],
      "metadata": {
        "id": "HKr4pcE5V967"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ###Check if there is conected gpu\n",
        "from IPython.display import clear_output\n",
        "\n",
        "try:\n",
        "  !nvidia-smi\n",
        "  clear_output()\n",
        "  print(\"Gpu running correctly\")\n",
        "except:\n",
        "  print(\"No gpu connected\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "L4etRKKxmtdT",
        "outputId": "f0cc8d08-c040-4a31-b8da-1bc1a698604b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gpu running correctly\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Requirements**"
      ],
      "metadata": {
        "id": "PrZZ09WUbjU3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OgK7KbslU1uU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e1f74ab-b77c-4baf-829b-401992d7f8a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Correctly installed model\n",
            "\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pip install wget\n",
        "import os\n",
        "import wget\n",
        "from IPython.display import clear_output\n",
        "\n",
        "#install diffusers for txt2image generation\n",
        "!pip install --upgrade diffusers[torch] torch\n",
        "clear_output()\n",
        "print(\"\\nSuccessfully installed diffusers[torch]\\n\")\n",
        "\n",
        "#install diffusers requirements\n",
        "!pip install --upgrade diffusers transformers accelerate safetensors OmegaConf\n",
        "clear_output()\n",
        "print(\"\\nInstalled txt2image requirements\\n\")\n",
        "\n",
        "#install interface requirements\n",
        "!pip install gradio requests\n",
        "clear_output()\n",
        "print(\"\\nInstalled interface requirements\\n\")\n",
        "\n",
        "#Install diffusers\n",
        "if not os.path.exists(\"/content/diffusers\"):\n",
        "  !mkdir /content/diffusers\n",
        "  %cd /diffusers\n",
        "  !git clone https://github.com/huggingface/diffusers\n",
        "  clear_output()\n",
        "  print(\"\\nSuccesfully installed Diffusers\\n\")\n",
        "  %cd /content\n",
        "else:\n",
        "  print(\"\\nDiffusers alredy installed\\n\")\n",
        "\n",
        "#Clone project repository\n",
        "if not os.path.exists(\"/content/adventure\"):\n",
        "  !mkdir /content/adventure\n",
        "  %cd /content/adventure\n",
        "  !git clone https://github.com/Y0z64/AI21-hackathon\n",
        "  clear_output()\n",
        "  print(\"\\nCorrectly cloned repository\")\n",
        "  %cd /content\n",
        "else:\n",
        "  print(\"\\nRepository already cloned\\n\")\n",
        "\n",
        "#Install model\n",
        "if not os.path.exists(\"/content/stable_diffusion\"):\n",
        "  !mkdir /content/stable_diffusion\n",
        "  %cd /content/stable_diffusion\n",
        "  !wget -O protogen_x34.safetensors \"https://civitai.com/api/download/models/4048?type=Model&format=SafeTensor\"\n",
        "  clear_output()\n",
        "  print(\"\\nCorrectly installed model\\n\")\n",
        "else:\n",
        "  clear_output()\n",
        "\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Convert model to diffusers**"
      ],
      "metadata": {
        "id": "7e4QI6xeg0Tf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython.display import clear_output\n",
        "\n",
        "if not os.path.exists(\"/content/stable_diffusion/model\"):\n",
        "  %cd /content/stable_diffusion\n",
        "  !mkdir model\n",
        "  !python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --from_safetensors --checkpoint_path /content/stable_diffusion/protogen_x34.safetensors --dump_path /content/stable_diffusion/model\n",
        "  clear_output()\n",
        "  print(\"Correctly converted model to Diffusers\\n\")\n",
        "  !rm /content/stable_diffusion/protogen_x34.safetensors\n",
        "else:\n",
        "  clear_output()\n",
        "  print(\"Model already converted\")\n",
        "\n",
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6yfQojVg65k",
        "outputId": "c9f852c1-39a5-4f08-e9d9-cdd6b8d13b1c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correctly converted model to Diffusers\n",
            "\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Start app**\n",
        "When the link appears click it to run it in your browser."
      ],
      "metadata": {
        "id": "w0v1qau4l44U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#add app to system path\n",
        "import sys\n",
        "\n",
        "#!cat /content/adventure/AI21-hackathon/adventures.py\n",
        "sys.path.append(\"/content/adventure/AI21-hackathon\")\n",
        "!cd /content/adventure/AI21-hackathon\n",
        "!pwd\n",
        "from adventures import *\n",
        "print(\"Custom app was imported correctly\")\n",
        "\n",
        "\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from IPython.display import Image\n",
        "from time import sleep\n",
        "import gradio as gr\n",
        "from IPython.display import clear_output\n",
        "#import app\n",
        "\n",
        "#Initialize image generator with custom pretrained model\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"/content/stable_diffusion/model\", torch_dtype=torch.float16)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "generator = torch.Generator(\"cuda\")\n",
        "\n",
        "#Get API KEY\n",
        "api_key = input(\"Input your API key: \")\n",
        "\n",
        "#start the adventure\n",
        "action_list, default_prpt = start_chat(fantasy_preset, start_1, api_key)\n",
        "\n",
        "def display_chatbot(input_message, Temperature, hystory=[]):\n",
        "    #call the chatbot\n",
        "    history, history, actions, message = chatbot_requests(input_message, action_list, default_prpt, Temperature, api_key, hystory)\n",
        "\n",
        "    #generate image\n",
        "    generation_prompt = generate_prompt(message, api_key)\n",
        "    image = pipe(generation_prompt, guidance_scale=7.5, num_inference_steps=15, generator=generator).images[0]\n",
        "\n",
        "    return history, history, actions, image\n",
        "\n",
        "#end adventure\n",
        "def clear_save():\n",
        "    global save\n",
        "    save = []\n",
        "\n",
        "#Interface design\n",
        "demo = gr.Interface(fn=display_chatbot,\n",
        "        inputs=[\"text\", gr.Slider(0, 1), \"state\"],\n",
        "        outputs=[\"chatbot\", \"state\", \"text\", \"image\"])\n",
        "\n",
        "#launch interface\n",
        "demo.launch(debug=True, share=True)\n",
        "\n",
        "#close everyhting\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "m8HRlTWyl_14"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}